在k8s上使用Ray对异构AI加速器进行ML增强 | Boost ML on Heterogeneous AI Accelerator with Ray on K8s - Tiejun Chen, VMware

https://kccncosschn2023.sched.com/event/1PTF9/nanok8szhi-rayai-fu-jmao-chan-ml-boost-ml-on-heterogeneous-ai-accelerator-with-ray-on-k8s-tiejun-chen-vmware

作为从云到边缘观察到的新兴趋势，人工智能工作负载倾向于通过顶级机器学习框架（如Ray）成功地进行管理和编排。但与此同时，各种供应商的人工智能加速器已经实现了人工智能加速。另一方面，存在着各种图编译器，如开放式TVM、英特尔OpenVINO、Nvidia TensorRT等，以改善机器学习性能，但存在碎片化的问题。因此，在现实世界中，用户在赋予这些异构人工智能加速器以不同软件加速方面面临挑战，因为缺乏一个自然支持它们的通用统一框架。在这里，我们想要回顾一下我们如何将透明的后端加速技术引入到Ray在k8s上与主流的ML图编译器无缝集成，以自动提升异构人工智能加速器上的机器学习性能。用户的人工智能应用程序无需进行任何代码更改。 
As an emerging trend being observed from cloud to edge, AI workloads tend to be managed and orchestrated successfully by the top ML frameworks like Ray. But at the same time, AI accelerations have been enabled by diverse vendors' AI accelerators. On the other hand, a variety of graph compilers like open TVM, Intel OpenVINO, Nvidia TensorRT, etc are existing to improve ML performance but fragmented. So, users have the challenges around empowering these heterogeneous AI accelerators with different software accelerations in the real world due to missing a general unified framework supporting them naturally. Here we'd like to review if-how we introduce our transparent backend acceleration technologies to boost ML performance automatically on heterogeneous AI accelerators with those ML graph compilers mainstream seamlessly with Ray on k8s. There is no code changes for user's AI applications.